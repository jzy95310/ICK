{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ca3aadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n",
      "warning in choleskies: failed to import cython module: falling back to numpy\n"
     ]
    }
   ],
   "source": [
    "import sys, os, random\n",
    "sys.path.insert(0, '../../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import Compose, ToTensor, Resize\n",
    "from kernels.nn import ImplicitConvNet2DKernel\n",
    "from kernels.kernel_fn import linear_kernel_nys, sq_exp_kernel_nys\n",
    "from model.ick import ICK\n",
    "from model.cmick import CMICK\n",
    "from benchmarks.cfrnet import Conv2DCFRNet\n",
    "from benchmarks.train_benchmarks import CFRNetTrainer\n",
    "from utils.train import CMICKEnsembleTrainer\n",
    "from utils.losses import *\n",
    "from utils.helpers import *\n",
    "\n",
    "# To make this notebook's output stable across runs\n",
    "random.seed(2020)\n",
    "np.random.seed(2020)\n",
    "torch.manual_seed(2020)\n",
    "torch.cuda.manual_seed(2020)\n",
    "torch.cuda.manual_seed_all(2020)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268acd90",
   "metadata": {},
   "source": [
    "# 1. Load and preprocess the images and demographic infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d354f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(train_ratio, test_ratio, random_state, include_images=True, demo_features=None):\n",
    "    def process_img(img, resize=(224,224), mode='L'):\n",
    "        # Convert the image to black-white and resize\n",
    "        assert isinstance(resize, tuple) and len(resize) == 2\n",
    "        transforms = Compose([ToTensor(), Resize(resize)])\n",
    "        img = transforms(img.convert(mode))\n",
    "        return np.array(img)\n",
    "    \n",
    "    demo_info_dir = '../../data/Covid_Montreal/metadata_PO.csv'\n",
    "    imgs_dir = '../../data/Covid_Montreal/images/'\n",
    "    col_names = ['offset','sex','age','RT_PCR_positive','survival','intubated','intubation_present', \n",
    "                 'went_icu', 'in_icu']\n",
    "    cols_to_normalize = ['offset','age']\n",
    "    if demo_features is None:\n",
    "        demo_features = col_names\n",
    "    else:\n",
    "        assert set(demo_features).issubset(set(col_names))\n",
    "    demo_info = pd.read_csv(demo_info_dir)\n",
    "    for c in demo_info.columns:\n",
    "        if c in cols_to_normalize:\n",
    "            scaler = StandardScaler()\n",
    "            demo_info[c] = scaler.fit_transform(demo_info[c].to_numpy().reshape(-1,1)).reshape(-1)\n",
    "    demo_info['Y'] = demo_info.apply(lambda row: row['Y0'] if row['treatment'] == 0 else row['Y1'], axis=1)\n",
    "\n",
    "    N = len(demo_info)\n",
    "    demo_info_train = demo_info.sample(n=int(train_ratio*N), random_state=random_state)\n",
    "    demo_info = demo_info.drop(demo_info_train.index)\n",
    "    demo_info_test = demo_info.sample(n=int(test_ratio*N), random_state=random_state)\n",
    "    demo_info_val = demo_info.drop(demo_info_test.index)\n",
    "    D_train, D_val, D_test = np.array(demo_info_train[demo_features]), np.array(demo_info_val[demo_features]), np.array(demo_info_test[demo_features])\n",
    "    X_train = np.array([process_img(x) for x in [Image.open(imgs_dir+list(demo_info_train['filename'])[i]) for i in range(len(demo_info_train))]])\n",
    "    X_val = np.array([process_img(x) for x in [Image.open(imgs_dir+list(demo_info_train['filename'])[i]) for i in range(len(demo_info_val))]])\n",
    "    X_test = np.array([process_img(x) for x in [Image.open(imgs_dir+list(demo_info_train['filename'])[i]) for i in range(len(demo_info_test))]])\n",
    "    T_train, T_val, T_test = np.array(demo_info_train[['treatment']]), np.array(demo_info_val[['treatment']]), np.array(demo_info_test[['treatment']])\n",
    "    Y_train, Y_val, Y_test = np.array(demo_info_train[['Y']]), np.array(demo_info_val[['Y']]), np.array(demo_info_test[['Y']])\n",
    "    Y0_train, Y0_val, Y0_test = np.array(demo_info_train[['Y0']]), np.array(demo_info_val[['Y0']]), np.array(demo_info_test[['Y0']])\n",
    "    Y1_train, Y1_val, Y1_test = np.array(demo_info_train[['Y1']]), np.array(demo_info_val[['Y1']]), np.array(demo_info_test[['Y1']])\n",
    "    \n",
    "    data_train, data_val, data_test = [T_train], [T_val], [T_test]\n",
    "    if include_images:\n",
    "        data_train.append(X_train)\n",
    "        data_val.append(X_val)\n",
    "        data_test.append(X_test)\n",
    "    if len(demo_features) > 0:\n",
    "        data_train.append(D_train)\n",
    "        data_val.append(D_val)\n",
    "        data_test.append(D_test)\n",
    "    data = {'X_train': X_train, 'T_train': T_train, 'D_train': D_train, 'Y_train': Y_train, 'Y0_train': Y0_train, 'Y1_train': Y1_train, \n",
    "            'X_val': X_val, 'T_val': T_val, 'D_val': D_val, 'Y_val': Y_val, 'Y0_val': Y0_val, 'Y1_val': Y1_val, \n",
    "            'X_test': X_test, 'T_test': T_test, 'D_test': D_test, 'Y_test': Y_test, 'Y0_test': Y0_test, 'Y1_test': Y1_test}\n",
    "    data_generators = create_generators_from_data(\n",
    "        x_train=data_train, y_train=Y_train, \n",
    "        x_val=data_val, y_val=Y_val,\n",
    "        x_test=data_test, y_test=Y_test, \n",
    "        train_batch_size=16, val_batch_size=16, test_batch_size=16, \n",
    "        drop_last=True\n",
    "    )\n",
    "    del X_train, X_val, X_test, D_train, D_val, D_test, T_train, T_val, T_test, Y_train, Y_val, Y_test\n",
    "    return data_generators, data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1010af",
   "metadata": {},
   "source": [
    "# 2. Build, train, and evaluate CMNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126028a",
   "metadata": {},
   "source": [
    "## 2.1 Image information only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "714d0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate_cmnn_ensemble_image_only(input_width, input_height, in_channels, data_generators, \n",
    "                                          data, lr, treatment_index=0):\n",
    "    alpha11, alpha12, alpha13 = 1.0, 1.0, 1.0\n",
    "    num_estimators = 10\n",
    "    \n",
    "    ensemble, ensemble_weights = [], {}\n",
    "    for i in range(num_estimators):\n",
    "        f11 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 512, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        f12 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 512, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        f13 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 512, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        baselearner = CMICK(\n",
    "            control_components=[f11], treatment_components=[f12], shared_components=[f13],\n",
    "            control_coeffs=[alpha11], treatment_coeffs=[alpha12], shared_coeffs=[alpha13], \n",
    "            coeff_trainable=True\n",
    "        )\n",
    "        ensemble.append(baselearner)\n",
    "    \n",
    "    # The index of \"T_train\" in \"data_train\" is 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optim = 'sgd'\n",
    "    optim_params = {\n",
    "        'lr': lr, \n",
    "        'momentum': 0.99,\n",
    "        'weight_decay': 1e-4\n",
    "    }\n",
    "    epochs, patience = 1000, 10\n",
    "    trainer = CMICKEnsembleTrainer(\n",
    "        model=ensemble,\n",
    "        data_generators=data_generators,\n",
    "        optim=optim,\n",
    "        optim_params=optim_params, \n",
    "        model_save_dir=None,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        patience=patience, \n",
    "        treatment_index=treatment_index\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    mean_test_pred, std_test_pred, y_test_true = trainer.predict()\n",
    "    y0_test, y1_test = data['Y0_test'], data['Y1_test']\n",
    "    pehe_test = np.sqrt(np.mean(((mean_test_pred[:,1] - mean_test_pred[:,0]) - (y1_test - y0_test)) ** 2))\n",
    "    print('PEHE (CMNN with image only):             %.4f' % (pehe_test))\n",
    "    \n",
    "    return pehe_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f53b6",
   "metadata": {},
   "source": [
    "## 2.2 Demographic information only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94d261db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate_cmnn_ensemble_demo_only(input_dim, data_generators, data, lr, treatment_index=0):\n",
    "    alpha11, alpha12, alpha13 = 1.0, 1.0, 1.0\n",
    "    num_estimators = 10\n",
    "    \n",
    "    ensemble, ensemble_weights = [], {}\n",
    "    for i in range(num_estimators):\n",
    "        f11 = ICK(\n",
    "            kernel_assignment=['ImplicitDenseNetKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitDenseNetKernel':{\n",
    "                    'input_dim': input_dim, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'num_layers_per_block': 1,\n",
    "                    'num_units': 512,\n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        f12 = ICK(\n",
    "            kernel_assignment=['ImplicitDenseNetKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitDenseNetKernel':{\n",
    "                    'input_dim': input_dim, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'num_layers_per_block': 1,\n",
    "                    'num_units': 512,\n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        f13 = ICK(\n",
    "            kernel_assignment=['ImplicitDenseNetKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitDenseNetKernel':{\n",
    "                    'input_dim': input_dim, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'num_layers_per_block': 1,\n",
    "                    'num_units': 512,\n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        baselearner = CMICK(\n",
    "            control_components=[f11], treatment_components=[f12], shared_components=[f13],\n",
    "            control_coeffs=[alpha11], treatment_coeffs=[alpha12], shared_coeffs=[alpha13], \n",
    "            coeff_trainable=True\n",
    "        )\n",
    "        ensemble.append(baselearner)\n",
    "    \n",
    "    # The index of \"T_train\" in \"data_train\" is 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optim = 'sgd'\n",
    "    optim_params = {\n",
    "        'lr': lr, \n",
    "        'momentum': 0.99,\n",
    "        'weight_decay': 1e-4\n",
    "    }\n",
    "    epochs, patience = 1000, 10\n",
    "    trainer = CMICKEnsembleTrainer(\n",
    "        model=ensemble,\n",
    "        data_generators=data_generators,\n",
    "        optim=optim,\n",
    "        optim_params=optim_params, \n",
    "        model_save_dir=None,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        patience=patience, \n",
    "        treatment_index=treatment_index\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    mean_test_pred, std_test_pred, y_test_true = trainer.predict()\n",
    "    y0_test, y1_test = data['Y0_test'], data['Y1_test']\n",
    "    pehe_test = np.sqrt(np.mean(((mean_test_pred[:,1] - mean_test_pred[:,0]) - (y1_test - y0_test)) ** 2))\n",
    "    print('PEHE (CMNN with demographic info only):             %.4f' % (pehe_test))\n",
    "    \n",
    "    return pehe_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ee5e93",
   "metadata": {},
   "source": [
    "## 2.3 Image + demographic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e79b11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate_cmnn_ensemble_image_demo(input_width, input_height, in_channels, demo_dim, data_generators, \n",
    "                                          data, lr, treatment_index=0):\n",
    "    alpha11, alpha12, alpha13 = 1.0, 1.0, 1.0\n",
    "    num_estimators = 10\n",
    "    \n",
    "    ensemble, ensemble_weights = [], {}\n",
    "    for i in range(num_estimators):\n",
    "        f11 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel','ImplicitDenseNetKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }, \n",
    "                'ImplicitDenseNetKernel':{\n",
    "                    'input_dim': demo_dim, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'num_layers_per_block': 1,\n",
    "                    'num_units': 512,\n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        f12 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel','ImplicitDenseNetKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }, \n",
    "                'ImplicitDenseNetKernel':{\n",
    "                    'input_dim': demo_dim, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'num_layers_per_block': 1,\n",
    "                    'num_units': 512,\n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        f13 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel','ImplicitDenseNetKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }, \n",
    "                'ImplicitDenseNetKernel':{\n",
    "                    'input_dim': demo_dim, \n",
    "                    'latent_feature_dim': 128, \n",
    "                    'num_blocks': 1, \n",
    "                    'num_layers_per_block': 1,\n",
    "                    'num_units': 512,\n",
    "                    'activation': 'relu'\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        baselearner = CMICK(\n",
    "            control_components=[f11], treatment_components=[f12], shared_components=[f13],\n",
    "            control_coeffs=[alpha11], treatment_coeffs=[alpha12], shared_coeffs=[alpha13], \n",
    "            coeff_trainable=True\n",
    "        )\n",
    "        ensemble.append(baselearner)\n",
    "        \n",
    "    # The index of \"T_train\" in \"data_train\" is 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optim = 'sgd'\n",
    "    optim_params = {\n",
    "        'lr': lr, \n",
    "        'momentum': 0.99,\n",
    "        'weight_decay': 1e-4\n",
    "    }\n",
    "    epochs, patience = 1000, 10\n",
    "    trainer = CMICKEnsembleTrainer(\n",
    "        model=ensemble,\n",
    "        data_generators=data_generators,\n",
    "        optim=optim,\n",
    "        optim_params=optim_params, \n",
    "        model_save_dir=None,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        patience=patience, \n",
    "        treatment_index=treatment_index\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    mean_test_pred, std_test_pred, y_test_true = trainer.predict()\n",
    "    y0_test, y1_test = data['Y0_test'], data['Y1_test']\n",
    "    pehe_test = np.sqrt(np.mean(((mean_test_pred[:,1] - mean_test_pred[:,0]) - (y1_test - y0_test)) ** 2))\n",
    "    print('PEHE (CMNN with image and demographic info):             %.4f' % (pehe_test))\n",
    "    \n",
    "    return pehe_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa95c9e",
   "metadata": {},
   "source": [
    "# 3. Build, train, and evaluate CMICK model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad6c9c",
   "metadata": {},
   "source": [
    "## 3.1 Image + all demographic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d9ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_evaluate_cmick_ensemble_image_demo(input_width, input_height, in_channels, demo_range, data_generators, \n",
    "                                           data, lr, treatment_index=0):\n",
    "    alpha11, alpha12, alpha13 = 1.0, 1.0, 1.0\n",
    "    num_estimators = 10\n",
    "    \n",
    "    ensemble, ensemble_weights = [], {}\n",
    "    for i in range(num_estimators):\n",
    "        f11 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel','ImplicitNystromKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 32, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }, \n",
    "                'ImplicitNystromKernel':{\n",
    "                    'kernel_func': linear_kernel_nys, \n",
    "                    'params': ['std','c','noise'], \n",
    "                    'vals': [1.,0.25,0.5], \n",
    "                    'trainable': [True,True,True], \n",
    "                    'alpha': 1e-5, \n",
    "                    'num_inducing_points': 32, \n",
    "                    'nys_space': demo_range\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        f12 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel','ImplicitNystromKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 32, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }, \n",
    "                'ImplicitNystromKernel':{\n",
    "                    'kernel_func': linear_kernel_nys, \n",
    "                    'params': ['std','c','noise'], \n",
    "                    'vals': [1.,0.25,0.5], \n",
    "                    'trainable': [True,True,True], \n",
    "                    'alpha': 1e-5, \n",
    "                    'num_inducing_points': 32, \n",
    "                    'nys_space': demo_range\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        f13 = ICK(\n",
    "            kernel_assignment=['ImplicitConvNet2DKernel','ImplicitNystromKernel'],\n",
    "            kernel_params={\n",
    "                'ImplicitConvNet2DKernel':{\n",
    "                    'input_width': input_width,\n",
    "                    'input_height': input_height, \n",
    "                    'in_channels': in_channels,\n",
    "                    'num_intermediate_channels': 64, \n",
    "                    'latent_feature_dim': 32, \n",
    "                    'num_blocks': 1, \n",
    "                    'activation': 'relu'\n",
    "                }, \n",
    "                'ImplicitNystromKernel':{\n",
    "                    'kernel_func': linear_kernel_nys, \n",
    "                    'params': ['std','c','noise'], \n",
    "                    'vals': [1.,0.25,0.5], \n",
    "                    'trainable': [True,True,True], \n",
    "                    'alpha': 1e-5, \n",
    "                    'num_inducing_points': 32, \n",
    "                    'nys_space': demo_range\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        baselearner = CMICK(\n",
    "            control_components=[f11], treatment_components=[f12], shared_components=[f13],\n",
    "            control_coeffs=[alpha11], treatment_coeffs=[alpha12], shared_coeffs=[alpha13], \n",
    "            coeff_trainable=True\n",
    "        )\n",
    "        ensemble.append(baselearner)\n",
    "    \n",
    "    # The index of \"T_train\" in \"data_train\" is 0\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optim = 'sgd'\n",
    "    optim_params = {\n",
    "        'lr': lr, \n",
    "        'momentum': 0.99,\n",
    "        'weight_decay': 1e-4\n",
    "    }\n",
    "    epochs, patience = 1000, 10\n",
    "    trainer = CMICKEnsembleTrainer(\n",
    "        model=ensemble,\n",
    "        data_generators=data_generators,\n",
    "        optim=optim,\n",
    "        optim_params=optim_params, \n",
    "        model_save_dir=None,\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        patience=patience, \n",
    "        treatment_index=treatment_index\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    mean_test_pred, std_test_pred, y_test_true = trainer.predict()\n",
    "    y0_test, y1_test = data['Y0_test'], data['Y1_test']\n",
    "    pehe_test = np.sqrt(np.mean(((mean_test_pred[:,1] - mean_test_pred[:,0]) - (y1_test - y0_test)) ** 2))\n",
    "    print('PEHE (CMICK with image and demographic info):             %.4f' % (pehe_test))\n",
    "    \n",
    "    return pehe_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9b41a",
   "metadata": {},
   "source": [
    "# 4. Benchmark 1: CFRNet (with image only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b854bec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate_cfrnet(input_width, input_height, in_channels, phi_depth, phi_width, h_depth, h_width, \n",
    "                            data_generators, data, lr, alpha, metric='W2', treatment_index=0):\n",
    "    cfrnet = Conv2DCFRNet(input_width, input_height, in_channels, phi_depth, phi_width, h_depth, h_width)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optim = 'sgd'\n",
    "    optim_params = {\n",
    "        'lr': lr, \n",
    "        'momentum': 0.99,\n",
    "        'weight_decay': 1e-4\n",
    "    }\n",
    "    epochs, patience = 1000, 10\n",
    "    trainer = CFRNetTrainer(\n",
    "        model=cfrnet,\n",
    "        data_generators=data_generators,\n",
    "        optim=optim,\n",
    "        optim_params=optim_params, \n",
    "        model_save_dir=None,\n",
    "        loss_fn=CFRLoss(alpha=alpha,metric=metric),\n",
    "        device=device,\n",
    "        epochs=epochs,\n",
    "        patience=patience, \n",
    "        treatment_index=treatment_index\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    y_test_pred, y_test_true = trainer.predict()\n",
    "    y0_test, y1_test = data['Y0_test'], data['Y1_test']\n",
    "    pehe_test = np.sqrt(np.mean(((y_test_pred[:,1] - y_test_pred[:,0]) - (y1_test - y0_test)) ** 2))\n",
    "    print('PEHE (CFRNet):             %.4f' % (pehe_test))\n",
    "    \n",
    "    return pehe_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695cfb9c",
   "metadata": {},
   "source": [
    "# Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1991b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started:\n",
      "\n",
      "Epoch 1/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 11s - loss 37.4104\n",
      "Validation:\n",
      "1s - loss 38.4525\n",
      "\n",
      "Epoch 2/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 35.4288\n",
      "Validation:\n",
      "1s - loss 35.8631\n",
      "\n",
      "Epoch 3/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 32.2364\n",
      "Validation:\n",
      "1s - loss 32.0704\n",
      "\n",
      "Epoch 4/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 27.9947\n",
      "Validation:\n",
      "1s - loss 26.2282\n",
      "\n",
      "Epoch 5/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 21.0966\n",
      "Validation:\n",
      "1s - loss 16.4202\n",
      "\n",
      "Epoch 6/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 12.5560\n",
      "Validation:\n",
      "1s - loss 8.4137\n",
      "\n",
      "Epoch 7/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 11.3652\n",
      "Validation:\n",
      "1s - loss 10.7975\n",
      "\n",
      "Epoch 8/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 10.7814\n",
      "Validation:\n",
      "1s - loss 8.0061\n",
      "\n",
      "Epoch 9/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 9.3234\n",
      "Validation:\n",
      "1s - loss 9.5578\n",
      "\n",
      "Epoch 10/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 9.8798\n",
      "Validation:\n",
      "1s - loss 9.2337\n",
      "\n",
      "Epoch 11/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 9.2170\n",
      "Validation:\n",
      "1s - loss 7.8058\n",
      "\n",
      "Epoch 12/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 8.4506\n",
      "Validation:\n",
      "1s - loss 7.2920\n",
      "\n",
      "Epoch 13/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 8.4954\n",
      "Validation:\n",
      "1s - loss 7.4808\n",
      "\n",
      "Epoch 14/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 8.2900\n",
      "Validation:\n",
      "1s - loss 7.2630\n",
      "\n",
      "Epoch 15/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 8.0536\n",
      "Validation:\n",
      "1s - loss 7.3277\n",
      "\n",
      "Epoch 16/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 8.0507\n",
      "Validation:\n",
      "1s - loss 7.5189\n",
      "\n",
      "Epoch 17/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 8.0198\n",
      "Validation:\n",
      "1s - loss 7.4624\n",
      "\n",
      "Epoch 18/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 7.9706\n",
      "Validation:\n",
      "1s - loss 7.3856\n",
      "\n",
      "Epoch 19/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 7.9652\n",
      "Validation:\n",
      "1s - loss 7.3801\n",
      "\n",
      "Epoch 20/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 7.8829\n",
      "Validation:\n",
      "1s - loss 7.3580\n",
      "\n",
      "Epoch 21/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 7.8474\n",
      "Validation:\n",
      "1s - loss 7.3330\n",
      "\n",
      "Epoch 22/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 7.8205\n",
      "Validation:\n",
      "1s - loss 7.3528\n",
      "\n",
      "Epoch 23/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 7.8301\n",
      "Validation:\n",
      "1s - loss 7.3522\n",
      "\n",
      "Epoch 24/1000\n",
      "Learning rate: 0.000050\n",
      "Training time - 9s - loss 7.8145\n",
      "Validation:\n",
      "1s - loss 7.3195\n",
      "\n",
      "Early stopping - patience reached\n",
      "Restoring the best model\n",
      "PEHE (CMNN with image only):             1.5310\n",
      "Training started:\n",
      "\n",
      "Epoch 1/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 38.4615\n",
      "Validation:\n",
      "0s - loss 37.3231\n",
      "\n",
      "Epoch 2/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 37.6356\n",
      "Validation:\n",
      "0s - loss 36.2064\n",
      "\n",
      "Epoch 3/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 36.4070\n",
      "Validation:\n",
      "0s - loss 34.6371\n",
      "\n",
      "Epoch 4/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 34.5701\n",
      "Validation:\n",
      "0s - loss 32.7908\n",
      "\n",
      "Epoch 5/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 32.7279\n",
      "Validation:\n",
      "0s - loss 30.7305\n",
      "\n",
      "Epoch 6/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 30.4814\n",
      "Validation:\n",
      "0s - loss 28.4901\n",
      "\n",
      "Epoch 7/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 28.2206\n",
      "Validation:\n",
      "0s - loss 26.0496\n",
      "\n",
      "Epoch 8/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 25.7711\n",
      "Validation:\n",
      "0s - loss 23.3213\n",
      "\n",
      "Epoch 9/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 22.8098\n",
      "Validation:\n",
      "0s - loss 20.0521\n",
      "\n",
      "Epoch 10/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 18.8932\n",
      "Validation:\n",
      "0s - loss 15.6151\n",
      "\n",
      "Epoch 11/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 14.0642\n",
      "Validation:\n",
      "0s - loss 8.5986\n",
      "\n",
      "Epoch 12/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 10.8253\n",
      "Validation:\n",
      "0s - loss 9.7970\n",
      "\n",
      "Epoch 13/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 9.1070\n",
      "Validation:\n",
      "0s - loss 7.5304\n",
      "\n",
      "Epoch 14/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 9.2625\n",
      "Validation:\n",
      "0s - loss 9.0961\n",
      "\n",
      "Epoch 15/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 9.4425\n",
      "Validation:\n",
      "0s - loss 8.7975\n",
      "\n",
      "Epoch 16/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 8.9146\n",
      "Validation:\n",
      "0s - loss 7.8995\n",
      "\n",
      "Epoch 17/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 8.4095\n",
      "Validation:\n",
      "0s - loss 7.1904\n",
      "\n",
      "Epoch 18/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 8.0433\n",
      "Validation:\n",
      "0s - loss 6.6848\n",
      "\n",
      "Epoch 19/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 8.0792\n",
      "Validation:\n",
      "0s - loss 6.7315\n",
      "\n",
      "Epoch 20/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 8.2187\n",
      "Validation:\n",
      "0s - loss 6.7485\n",
      "\n",
      "Epoch 21/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 8.2345\n",
      "Validation:\n",
      "0s - loss 6.6575\n",
      "\n",
      "Epoch 22/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 8.0569\n",
      "Validation:\n",
      "0s - loss 6.6509\n",
      "\n",
      "Epoch 23/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.9873\n",
      "Validation:\n",
      "0s - loss 6.7575\n",
      "\n",
      "Epoch 24/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.9494\n",
      "Validation:\n",
      "0s - loss 6.8329\n",
      "\n",
      "Epoch 25/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.9315\n",
      "Validation:\n",
      "0s - loss 6.9226\n",
      "\n",
      "Epoch 26/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.9351\n",
      "Validation:\n",
      "0s - loss 6.9433\n",
      "\n",
      "Epoch 27/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.9391\n",
      "Validation:\n",
      "0s - loss 6.8942\n",
      "\n",
      "Epoch 28/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.8520\n",
      "Validation:\n",
      "0s - loss 6.8426\n",
      "\n",
      "Epoch 29/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.9043\n",
      "Validation:\n",
      "0s - loss 6.8051\n",
      "\n",
      "Epoch 30/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.8901\n",
      "Validation:\n",
      "0s - loss 6.7576\n",
      "\n",
      "Epoch 31/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.8378\n",
      "Validation:\n",
      "0s - loss 6.7189\n",
      "\n",
      "Epoch 32/1000\n",
      "Learning rate: 0.000010\n",
      "0s for 32 steps - 0ms/step - loss 7.8816\n",
      "Validation:\n",
      "0s - loss 6.7096\n",
      "\n",
      "Early stopping - patience reached\n",
      "Restoring the best model\n",
      "PEHE (CFRNet):             1.5022\n",
      "PEHE (CMNN with image only):             1.5310\n",
      "PEHE (CFRNet):             1.5022\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    train_ratio, test_ratio = 0.60, 0.20\n",
    "    \n",
    "    # CMNN\n",
    "    data_generators, data = load_and_preprocess_data(train_ratio, test_ratio, random_state=1, demo_features=[])\n",
    "    input_width, input_height, in_channels = data['X_train'].shape[2], data['X_train'].shape[3], data['X_train'].shape[1]\n",
    "    sqrt_pehe_cmnn_image_only = fit_evaluate_cmnn_ensemble_image_only(input_width, input_height, in_channels, \n",
    "                                                                      data_generators, data, lr=5e-5)\n",
    "#     data_generators, data = load_and_preprocess_data(train_ratio, test_ratio, random_state=1, include_images=False)\n",
    "#     demo_input_dim = data['D_train'].shape[1]\n",
    "#     sqrt_pehe_cmnn_demo_only = fit_evaluate_cmnn_ensemble_demo_only(demo_input_dim, data_generators, data, lr=5e-4)\n",
    "#     data_generators, data = load_and_preprocess_data(train_ratio, test_ratio, random_state=1)\n",
    "#     demo_input_dim = data['D_train'].shape[1]\n",
    "#     sqrt_pehe_cmnn_image_demo = fit_evaluate_cmnn_ensemble_image_demo(input_width, input_height, in_channels, \n",
    "#                                                                       demo_input_dim, data_generators, data, lr=1e-4)\n",
    "    \n",
    "    # CMICK\n",
    "#     data_generators, data = load_and_preprocess_data(train_ratio, test_ratio, random_state=1, demo_features=['age'])\n",
    "#     input_width, input_height, in_channels = data['X_train'].shape[2], data['X_train'].shape[3], data['X_train'].shape[1]\n",
    "#     demo_range = [[np.min(data['D_train'][:,d]), np.max(data['D_train'][:,d])] for d in range(data['D_train'].shape[1])]\n",
    "#     sqrt_pehe_cmick_image_demo = fit_evaluate_cmick_ensemble_image_demo(input_width, input_height, in_channels, \n",
    "#                                                                         demo_range, data_generators, data, lr=1e-4)\n",
    "    \n",
    "    # Benchmarks\n",
    "    data_generators, data = load_and_preprocess_data(train_ratio, test_ratio, random_state=1, demo_features=[])\n",
    "    input_width, input_height, in_channels = data['X_train'].shape[2], data['X_train'].shape[3], data['X_train'].shape[1]\n",
    "    sqrt_pehe_cfrnet_wass = fit_and_evaluate_cfrnet(\n",
    "        input_width, input_height, in_channels, 2, 512, 2, 512, data_generators, data, lr=1e-5,\n",
    "        alpha=1e-2, metric='W2'\n",
    "    )\n",
    "    \n",
    "    print('PEHE (CMNN with image only):             %.4f' % (sqrt_pehe_cmnn_image_only))\n",
    "#     print('PEHE (CMNN with demographic info only):             %.4f' % (sqrt_pehe_cmnn_demo_only))\n",
    "#     print('PEHE (CMNN with image and demographic info):             %.4f' % (sqrt_pehe_cmnn_image_demo))\n",
    "#     print('PEHE (CMICK with image and demographic info):             %.4f' % (sqrt_pehe_cmick_image_demo))\n",
    "    print('PEHE (CFRNet):             %.4f' % (sqrt_pehe_cfrnet_wass))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
